<!DOCTYPE html>
<html>

    <head>
        <meta charset="utf-8">
        <meta content="width=device-width, initial-scale=1" name="viewport">
        <link rel="stylesheet" href="/assets/css/main.css">

        <!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Joe | nothing</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Joe" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="nothing" />
<meta property="og:description" content="nothing" />
<link rel="canonical" href="http://localhost:4000/" />
<meta property="og:url" content="http://localhost:4000/" />
<meta property="og:site_name" content="Joe" />
<link rel="next" href="http://localhost:4000/page2" />
<script type="application/ld+json">
{"url":"http://localhost:4000/","headline":"Joe","name":"Joe","description":"nothing","@type":"WebSite","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

    </head>

    <body style="background-color: rgba(220, 238, 203, 0.781)">
        <script async src="/assets/js/theme.min.js"></script>

        <header>
            
        </header>

        <main>
            <article>
                <h1 class="headline">Joe</h1>

<div class="article-list">
  
  <h2><a href="/2020/02/01/Java-Resizable-Array.html">【译】Java实现大小可变的数组 </a></h2>
  <small>February 01, 2020</small>
  <p>Java实现大小可变的数组


  有时为了快速的访问数据（特别是byte类型），需要将数据放入一个单独且连续的数组中，且数组至少是能够可扩张的。由于Java中的数组是不能够改变其大小的，所以使用数组本身是不能够满足需求的。因此，为了能够容纳原生类型并且可改变其大小的数组，需要自己动手实现。


为什么不使用ArrayList？

有人可能会想到使用ArrayList来实现刚才说的需求。当然是可以的，前提是满足以下任意条件：

  数组中存储的类型是对象类型。
  数组中存储的是原生类型，且不关心性能和内存。


Java中的ArrayList类只能存储对象类型的数据，不适用于原生类型（例如byte，int，long等）。如果是使用了ArrayList存储原生类型这些数据就会变自动的装箱为对应对象存入ArrayList中，并会在使用的时候自动拆箱为原生类型。由于涉及到了拆箱和装箱机制，当你想要优化提升性能的时候ArrayList不是你想的。

除此之外，存储装箱后的原生类型会带来额外的内存负担。

实现代码 - GitHub Repository

本教程的实现代码放置于GitHub方便访问：）

https://github.com/jjenkov/java-resizable-array

代码由3个Java类和2个单元测试组成

可变大小的数组使用场景

想想你有一个服务正在接受各种大小不同的消息。有一些消息大小很小（例如小于4kb），其他则是一些1mb左右的或者更大的消息数据。如果服务端不知道将要接收的数据大小，就不能为将要接收的消息预先分配好内存空间。代替方式是“超额分配”，意思是分配一块足够大的内存空间来接收消息（最大消息不超过5mb，那么每个消息块则分配6mb的内存）。

如果服务端同一时间正从多个链接（100K+）中接收消息，我们必须限制每一条消息所需要分配的内存大小。不能直接按照最大消息大小（例如 1mb或16mb）来给每一条消息分配内存。这样随着连接数和接收消息数的增加，很快就会耗尽服务器内存！100.000 x 1MB = 100GB (大概可以想象一下).

所以我们需要在接收消息前尽可能的分配小的buffer，当小buffer不足以接收大消息数据是我们就需要扩容这个buffer。

数组的扩容代价高昂

为了扩容一个数组你需要：

1.分配一个新的更大的数组。

2.将旧数组的数据拷贝到新数组中。

3.回收旧数组。

这一些列的操作代价高昂（特别是性能敏感的应用）！特别是随着旧数组数据越多拷贝数据到新数组这个操作的代价就越大。

注意，在一些带有垃圾回收机制的语言中（例如Java，C#等）尽管你没有明确指令回收旧数组，虚拟机也会为你执行此操作，所以迟早都需要付清回收操作的代价。

最小数组的扩容

为了将损失降低到最低，你需要尽可能减少数组扩容的次数，尽量创建一个足够大的数组来保存全部的消息数据。

如果我们接收的大部分消息都是小数据，我们可以先使用小buffer来接收。如果消息大小超过来小buffer的大小，我们就分配一个新的中等大小的数组并且将旧数组中的数据拷贝到新分配的数组中。同样当消息大小超过了中等大小的buffer，就创建一个更大的数组并拷贝过去。这个大的数组需要足够大，大到能够容纳一整个消息数据。如果消息的大小太大以至于不能够处理，那么服务端就应该拒绝接收该消息。

采用这样的策略，大部分的消息只会占用较小的buffer。这样有利于服务器内存的使用。100.000 x 4KB (小的buffer) 只需要400MB。大部分的服务器都能够承受。
即使是4GB（1.000.000 x 4KB）现代的服务器也是可以支撑的。

可扩容数组设计

可扩容数组有两个组件组成：


  ResizableArray
  ResizableArrayBuffer


ResizableArrayBuffer包含一个单一的，大数组。这个数组分为三个部分。第一部分是为了存储小的数组，第二个是为了存储较大的数组，最后一个是存储大数组。

ResizableArray代表了一个单一的，可扩容的数组，接收到的数据存储与这个数组中的ResizableArrayBuffer里。

这里有一个图来解释ResizableArrayBuffer中的三部分是如何划分的。



整个ResizableArrayBuffer的大数组中保留一个数据大小的间隙(small, medium, large)，我们需要确保每个数据块都不会被完全充满。例如，接收的small数据块不能占满medium和large的内存区块。同样的large数据块不能占满small和medium的内存区块。

刚开始的时候消息块都是从small数据块开始填充的，如果small数组块被用尽，那么将不会分配新的数组块了，不管meidum块和large块是否还有剩余的空间。

然而，存在一种很小的可能是small数组块占据了整个数组块的大部分空间。

即使small数组块已经被使用完了，也存在一种可能将small消息块的数据增长为medium和large的消息块。

优化选项

也可以使用一个单一的数组块来优化整个数组。因为有时一个新的数组块被分配后立马就需要被扩容。在这种情况下你不需要将旧数据拷贝到新的数组块中。你只需要简单的“扩展”这个数组块使其包含两个数组块一个旧的数组块一个新的数组块，并将新的数据写入新的数组块中。这样当一个内存块需要被“扩展”到下一个连续的块中时就节约了数组拷贝的成本。

上述方案存在的缺点是，当不可能将数组块扩展到下一个内存块中，拷贝数据任然是必须的。因此需要进行一次是否可扩展的检查操作。除此之外，如果你使用了一个small数组块，那么拓展操作将会比使用medium和large数组块更加频繁。

保持跟踪和回收数据块

ResizableArrayBuffer中的大数组被分为三部分。每一部分又被分为一个更小的块。每个块在每个部分都是同样的大小。例如，在small部分中的所有数据块都是small大小的数据块，在meidum部分都是meidum大小的数据块。在large部分也是同理。

当在一个部分的所有块都是同样大小时，才能更加容易保持跟踪使用过的块和没使用的块的情况。你可以简单的将每一个块所在的索引位置保存在一个队列中。每个部分都需要一个这样的队列。最终，需要一个队列来保存跟踪small块的使用情况，一个队列来保存meidum块的使用情况，一个队列来保存large块的使用情况。

从任何一个部分分配一个块的操作就可以简单的等价于从对应部分的队列中拿走空闲块的所在的索引。回收一个块的操作就可以看作放置一个索引到对应的队列中。

扩容并写入数据

可扩容的数组回自行执行扩容操作在你写入数据的时候。如果你尝试写入比数组当前分配的块更多的数据时，数组就会分配一个新的更大的块并拷贝写入的数据到这个新的块中。之前的那个小的数据块就会被释放回收。

释放数组块

一旦你使用完了一个可扩容的数组，你应该再次释放它，这样就可以用于存储其他的消息数据了。

如何使用ResizableArrayBuffer

展示如何使用一个ResizableArrayBuffer（代码来自GitHub）。

创建一个

首先你需要创建一个ResizableArrayBuffer。

int smallBlockSize  =    4 * 1024;
int mediumBlockSize =  128 * 1024;
int largeBlockSize  = 1024 * 1024;

int smallBlockCount  = 1024;
int mediumBlockCount =   32;
int largeBlockCount  =    4;

ResizableArrayBuffer arrayBuffer =
        new ResizableArrayBuffer(
                smallBlockSize , smallBlockCount,
                mediumBlockSize, mediumBlockCount,
                largeBlockSize,  largeBlockCount);


这个例子创建了一个含有4kb的small数组块，128kb的meidum数组块，1mb的large数组块 ResizableArrayBuffer ，并且包含1024个small数组块（一共可存储4mb的数据），32个medium数组块（也是共4mb）和4个large数组块（共4mb），整个数组可存储12mb的数据。

获取一个ResizableArray实例

通过调用 ResizableArrayBuffer的 getArray()方法。

ResizableArray resizableArray = arrayBuffer.getArray();


这样获取到一个最小大小的ResizableArray的实例（预先分配容量为4kb）。

ResizableArray中写入数据

通过调用 ResizableArray的 write()方法写入数据。ResizableArray类只包含一个write()方法，该方法接收一个 ByteBuffer作为参数。

ByteBuffer byteBuffer = ByteBuffer.allocate(1024);

for(int i=0; i &lt; 1024; i++){
    byteBuffer.put((byte) i);
}
byteBuffer.flip():

int bytesCopied = resizableArray.write(byteBuffer);


上述代码将 ByteBuffer 拷贝到 ResizableArray的数组块中。write()方法的返回值为从 ByteBuffer 中拷贝bytes的数量。

为了防止 ByteBuffer中的数据量大于当前ResizableArray分配的大小，ResizableArray会尝试扩容来容纳 ByteBuffer中的数据。如果ResizableArray已经扩容的到最大且无法装下 ByteBuffer中的数据时，write()方法就会返回-1，ByteBuffer中的数据自然也不会拷贝到ResizableArray中。

ResizableArray读取数据

当从ResizableArray中读取数据时相当于直接从ResizableArray中的数组中直接读取。ResizableArray类中包含公开的属性有：

public byte[] sharedArray = null;
public int    offset      = 0;
public int    capacity    = 0;
public int    length      = 0;


sharedArray属性持有所有ResizableArray实例的数据的数组的引用。这样的数组也存在于ResizableArrayBuffer中。

offset属性保存的ResizableArray的数据块起始位置的索引。

capacity属性表示ResizableArray数据块的大小。

length属性表示ResizableArray实际使用的数据块数量。

从ResizableArray中读取数据相当于读取 sharedArray[offset] 到 sharedArray[offset + length - 1] 段的数据。

释放ResizableArray

一旦使用完了ResizableArray，就需要调用 free()方法来释放数组。

resizableArray.free();


调用后会归还所占用的数据块到对应的数据块队列中，不论数据块分配的是多大的大小。

总结

跟Java中ArrayList实现方式有点类似。为了提升性能尽量要使用原生数据类型，时刻注意数据的回收利用。

引用

1.resizable-array
</p>
  
  <h2><a href="/2019/12/04/Learning-HTTP-Protocol.html">HTTP Note - 01 </a></h2>
  <small>December 04, 2019</small>
  <p>TCP连接相关


  并行连接：会消耗更多的资源（比如内存），也会受到带宽的限制，打开连接数量有限，会受到TCP慢启动和拥塞适应的影响。所以也不一定快。用户体验上会感觉快了。
  持久连接：在一个HTTP事务完成之后不关闭连接，直到服务器或客户端通知关闭连接，可以避免TCP慢启动，进入已调协状态，提高传输效率。HTTP/1.0 使用的是 Connection：keep-alive关键字进行标记是否保持连接，默认是关闭的。HTTP/1.1 默认开启了持久连接，如果在首部没法标记：Connection：close就默认为开启持久连接。
  代理对于HTTP报文的某些字段并不会转发（比如Connection字段等）
  管道化连接：在HTTP/1.1的持久连接的基础上开通管道，将多条请求窜行发送。必须保证有序的应答，失败重试机制可能无法适用于POST这样的非幂等请求。
  TCP是双向连接（输入和输出），当输入端被关闭然而数据并没有传输完，就会受到操作系统的异常提示“连接已经被充值”（难怪之前做DHT的时候老是遇到这个reset exception) 关闭输入通道比较危险，关闭输出相对安全


代理


  连接两个或多个使用相同协议的应用程序
  通过代理起到流量监控、访问控制、缓存、服务器加速（反向代理）
  通过将代理服务器部署在网络结构中的不同位置来实现不同的功能 （可以自己实现流量监控或者匿名功能？）


如何让流量流向代理服务器？（基于如何获取HTTP的流量信息）


  修改客户端
  修改网络 （很黑客）
  修改DNS的命名空间 （很黑客）
  修改Web服务器


HTTP/1.1存在的问题


  复杂性，实现难度较大
  可拓展性，协议拓展没有兼容性
  性能
  传输协议的依赖，依赖于TCP/IP网络协议栈


为了解决以上的问题，成了1997年HTTP-NG组，然而在一年之后就解散了（由于当时HTTP/1.1还没有普及，所以暂时停止了重构HTTP协议，再后来HTTP/2.0就来了）

如何保存用户状态

周所周知HTTP是无状态的，那么早期的大佬们是如何保存用户的状态的呢？


  胖URL：通过将用户登录后生产的为ID带到每一个URL中标示用户。然而这个方法问题多到💥。
  Cookie技术：由网景公司开发的技术，一致沿用至今。Cookie的基本思想是让浏览器累积一组服务器特有的的信息，每次都将这些信息带上访问服务器。Cookie有两个版本：0和1。现在大规模使用的都是由网景公司制定的版本0（因为1版本太复杂了吧）


问题


  什么是幂等？（答：如果一个事务，不管执行多少次结果都是相等的，这个事务就是幂等的。）
  什么是事务？（答：HTTP中指的是一次HTTP请求的完整流程。）


总结

阅读完《HTTP权威指南》，共耗时5～6个小时，该书是基于HTTP/1.1版本进行讲解的（现在已经有HTTP/2.0版本）很多已经过时或者内容与HTTP没有太多关联的章节都跳过了。这个书是一个HTTP协议的大致介绍，讲解的内容不是很细，还有很多内容都是过时的内容（毕竟出版比较久了）。由于内容比较简单笔记也做的不多。总的来说让我对HTTP协议有了基本的认识和了解，了解了HTTP协议的一个进化过程，通过从HTTP/0.9到HTTP/1.1的这个过程遇到很多web开发中比较常见的问题（比如代理、缓存、DNS解析、认证机制等）。也引出了TCP/IP的重要性，毕竟HTTP是属于应用层的协议，涉及到的内容不会太过于复杂，对于TCP、IP这样的协议属于传输层更加靠近底层会复杂许多。
</p>
  
  <h2><a href="/2019/10/26/Dependence-Injecting.html">Dependence Injecting </a></h2>
  <small>October 26, 2019</small>
  <p>What is Dependency injection

依赖注入（DI）指的通过一个对象依赖另一个对象的一种技术方式，例如在Client对象中依赖一个Service类，我们所做的方式不是在Client对象中创建一个新的Service类或者去寻找一个Service类，而是通过把Service类当作为Client对象的一个状态或者说一个属性传递给Client对象。

依赖注入（DI）的意图是想实现程序的解藕（SoC Separation of Concerns），也是设计模式的一种，让程序变成相对独立的部分，每个部分完成独立的功能，保持功能单一性原则。这样能够提高代码的重用性。

依赖注入（DI）属于Ioc（Inversion of Control）技术中的一种，主要思想就是屏蔽Client对象对如何创建Server过程的感知，Client不需要知道怎么创建Service，相应的注入实现会代替完成这项工作。将构造Service的能力从Client中分离出来。

依赖注入中存在四种角色：


  被依赖的服务提供者
  依赖服务的客户端
  服务提供者的统一接口
  创建和传递服务的注入者


使用过Spring的开发者一定很熟悉的。

Java相关的依赖注入框架CDI有很多，就我所知道的框架有： Weld 新框架Quarkus的依赖注入好像用的就是这一种框架, Spring耳熟能详的Spring全家桶，运行时的依赖注入，所以启动的时候会很慢, Play frameworkscala写的web框架

What’s the benift of DI

综上所述依赖注入（DI）主要是为了解决一下问题：


  如何独立出应用或类的创建方式？
  如何复用一个已经创建好的类？
  如何在单独的配置文件中指定创建对象的方式？
  应用程序如何支持不同的配置？


以Spring开发为例,我们可以使用 @Autowired 注解很快的注入一个依赖的Service类

public class Client{

    @Autowried
    private ServiceA serviceA;

    public void do(){
        serviceA.doService();
    }
}


如果我们不使用依赖注入的方式是如何实现呢？
public class Client{

    private final ServiceA serviceA=new ServiceA();

    public void do(){
        serviceA.doService();
    }

}

看起来好像也没有什么变化，就是使用new ServiceA()创建了一个对象而已。但是假如创建ServiceA的方法需要更多的构造参数呢？比如需要Dao层的支持，那么代码就会变成这样：
public class Client{

    private final UserRepository userRepository;
    private final ClientRepository clientRepository;

    private final ServiceA serviceA=new ServiceA(userRepository,clientRespository);
}

这样一来Client就会为了创建Service类引入更多与自身无关的类，让Client变得臃肿不好维护，如果需要在另一个Client中使用这个Service那么还得将上面代码拷贝过去，又会增加重复代码的坏味道。或则说当Service类的构造方法改变了，那么所有用到它的Client类都需要修改相应的代码。

所有如果使用了依赖注入的方式实现代码逻辑会有以下好处：

  代码更加清晰明朗，增加可读性，因为代码都一个单独的功能
  Client类变得更加灵活，有选择性的依赖需要的Service类
  依赖注入隔离类Client和Service，不仅提高了Service代码的重用性，还让代码可以更好的进行单元测试


当然有好处就有坏处的：

  由于创建类的工作是不可见的，各个框架会有不同的实现细节。
  引入额外的依赖，而且会创建很多类或接口（总得有个CDI框架吧，Spring打包出来还是挺大的）
  会增加启动时间（Spring就是一个典型的例子）


DI in Spring

在我看来，在Java中实现DI不是一件困难的事情，主要是考虑实现的DI会遇到什么问题。比如使用Spring的DI：

  Bean是Singleton的
  可以检查到Cycle Dependence
  保证每次获取的实例都是最新的（例如在Controller中获取到的HttpSession）


以上是目前使用Spring的时候能想到的关键点。

在Spring中依赖注入的方式主要有三种：

  构造注入，通过反射并调用类的构造函数进行创建实例，默认使用的是无参数的构造方法。
  Set方法注入，顾名思义就是调用Set方法将需要的值注入到类中。
  最常用的注解注入，主要依靠的是 JSR-250 @Resource｜ Spring @Autowired ｜ JSR-330 @Inject  注解。


官方文档中说明了@Autowired默认使用的ByType进行注入，@Resource默认使用的是ByName进行注入

//map的key只能是String会被注入成Bean的名字，value是能够类型匹配上的Bean实例
//这样就能后去整个应用的所有Bean了
@Autowired
private Map&lt;String,Object&gt; maps;


构造注入与Set注入的区别：

  构造注入是强制性的依赖，set方法注入是选择性的依赖。Spring team推荐使用的是构造注入的方式（难怪IDEA中使用@Autowired注解的时候老是提示使用构造的方式），构造注入提供工参数的null检查而且会将参数作为一个不可变的对象来使用。注意不要在构造方法中使用过多的构造参数了，会产生坏味道的。


首先来看一下Spring是如何扫描类的吧。

一下代码使用的SpringBoot 2.2版本

1.扫描basePackage下的class文件。

2.筛选是否标记为Component的类。

ClassPathScanningCandidateComponentProvider.java
private Set&lt;BeanDefinition&gt; scanCandidateComponents(String basePackage) {
		Set&lt;BeanDefinition&gt; candidates = new LinkedHashSet&lt;&gt;();
		try {
			String packageSearchPath = ResourcePatternResolver.CLASSPATH_ALL_URL_PREFIX +
					resolveBasePackage(basePackage) + '/' + this.resourcePattern;
                    //通过basePackage获取当前路径下的class文件信息
			Resource[] resources = getResourcePatternResolver().getResources(packageSearchPath);
			boolean traceEnabled = logger.isTraceEnabled();
			boolean debugEnabled = logger.isDebugEnabled();
			for (Resource resource : resources) {
				if (traceEnabled) {
					logger.trace("Scanning " + resource);
				}
				if (resource.isReadable()) {
					try {
						MetadataReader metadataReader = getMetadataReaderFactory().getMetadataReader(resource);
                        //筛选class
						if (isCandidateComponent(metadataReader)) {
							ScannedGenericBeanDefinition sbd = new ScannedGenericBeanDefinition(metadataReader);
							...
}


PathMatchingResourcePatternResolver.java
Assert.notNull(locationPattern, "Location pattern must not be null");
		if (locationPattern.startsWith(CLASSPATH_ALL_URL_PREFIX)) {
			// a class path resource (multiple resources for same name possible)
			if (getPathMatcher().isPattern(locationPattern.substring(CLASSPATH_ALL_URL_PREFIX.length()))) {
				// a class path resource pattern
				return findPathMatchingResources(locationPattern);
			}
			else {
				// all class path resources with the given name
				return findAllClassPathResources(locationPattern.substring(CLASSPATH_ALL_URL_PREFIX.length()));
			}
		}
		else {
			// Generally only look for a pattern after a prefix here,
			// and on Tomcat only after the "*/" separator for its "war:" protocol.
			int prefixEnd = (locationPattern.startsWith("war:") ? locationPattern.indexOf("*/") + 1 :
					locationPattern.indexOf(':') + 1);
			if (getPathMatcher().isPattern(locationPattern.substring(prefixEnd))) {
				// a file pattern
				return findPathMatchingResources(locationPattern);
			}
			else {
				// a single resource with the given name
				return new Resource[] {getResourceLoader().getResource(locationPattern)};
			}
		}


2.从CachingMetadataReaderFactory获取扫描到的类信息并装配成一个Configuration（表示定义类的一些行为和依赖关系）
protected final void parse(@Nullable String className, String beanName) throws IOException {
		Assert.notNull(className, "No bean class name for configuration class bean definition");
		MetadataReader reader = this.metadataReaderFactory.getMetadataReader(className);
		processConfigurationClass(new ConfigurationClass(reader, beanName));
	}


3.不断得调用ConfigurationClassParser中doProcessConfigurationClass方法解析定义的注解的行为，并根据注解扫描加载相关的类（执行同样的步骤）
// Recursively process the configuration class and its superclass hierarchy.
		SourceClass sourceClass = asSourceClass(configClass);
		do {
			sourceClass = doProcessConfigurationClass(configClass, sourceClass);
		}
		while (sourceClass != null);


扫描类步骤
if (configClass.getMetadata().isAnnotated(Component.class.getName())) {
			// Recursively process any member (nested) classes first
			processMemberClasses(configClass, sourceClass);
}

		// Process any @PropertySource annotations
        ...
        // Process any @ComponentScan annotations
        ...
        // Process any @Import annotations
        ...
        // Process any @ImportResource annotations
        ...
        // Process individual @Bean methods
        ...
        // Process default methods on interfaces
        ...
        // Process superclass, if any
        ...
        // No superclass -&gt; processing is complete


以上步骤完成之后还没有正式的初始化Bean

4.把装配好的Bean按照依赖关系排好序
sortPostProcessors(currentRegistryProcessors, beanFactory);


5.之后会执行一些一系列的postProcess操作，其中使用到了CGLIB的字节码增强处理。
public Class&lt;?&gt; enhance(Class&lt;?&gt; configClass, @Nullable ClassLoader classLoader) {
		if (EnhancedConfiguration.class.isAssignableFrom(configClass)) {
			if (logger.isDebugEnabled()) {
				logger.debug(String.format("Ignoring request to enhance %s as it has " +
						"already been enhanced. This usually indicates that more than one " +
						"ConfigurationClassPostProcessor has been registered (e.g. via " +
						"&lt;context:annotation-config&gt;). This is harmless, but you may " +
						"want check your configuration and remove one CCPP if possible",
						configClass.getName()));
			}
			return configClass;
		}
		Class&lt;?&gt; enhancedClass = createClass(newEnhancer(configClass, classLoader));
		if (logger.isTraceEnabled()) {
			logger.trace(String.format("Successfully enhanced %s; enhanced class name is: %s",
					configClass.getName(), enhancedClass.getName()));
		}
		return enhancedClass;
	}


6.最后在准备工作都完成之后开始初始化非懒加载的Bean。
// Instantiate all remaining (non-lazy-init) singletons.
beanFactory.preInstantiateSingletons();

BeanFactory是创建Bean的主要类具体的实现是在 AbstractBeanFactory中的 doGetBean方法中

// Trigger initialization of all non-lazy singleton beans...
		for (String beanName : beanNames) {
			RootBeanDefinition bd = getMergedLocalBeanDefinition(beanName);
			if (!bd.isAbstract() &amp;&amp; bd.isSingleton() &amp;&amp; !bd.isLazyInit()) {
				if (isFactoryBean(beanName)) {
					Object bean = getBean(FACTORY_BEAN_PREFIX + beanName);
					if (bean instanceof FactoryBean) {
						final FactoryBean&lt;?&gt; factory = (FactoryBean&lt;?&gt;) bean;
						boolean isEagerInit;
						if (System.getSecurityManager() != null &amp;&amp; factory instanceof SmartFactoryBean) {
							isEagerInit = AccessController.doPrivileged((PrivilegedAction&lt;Boolean&gt;)
											((SmartFactoryBean&lt;?&gt;) factory)::isEagerInit,
									getAccessControlContext());
						}
						else {
							isEagerInit = (factory instanceof SmartFactoryBean &amp;&amp;
									((SmartFactoryBean&lt;?&gt;) factory).isEagerInit());
						}
						if (isEagerInit) {
							getBean(beanName);
						}
					}
				}
				else {
					getBean(beanName);
				}
			}
		}


具体实例化的时候会有不同的InstanceStrategy，如果是使用默认的构造方法（就是没有注解标记的）就会使用 SimpleInstantiationStrategy 反射默认的构造方法，如果是使用了注解，就会使用 CglibSubclassingInstantiationStrategy 生产代理类。

7.最后通知容器Bean创建完成。

Consolation

以上就是Spring创建Bean的一个大概流程。由于源码多而杂很多细节的地方都没有仔细去看，本次主要是想知道Spring是创建Bean的一个流程，从扫描类到解析类的信息，再到将类信息转化可解释的配置类，再统一将配置类按照不同的实例化策略进行实例化，再到实例化之后的后处理操作。整个过程看起来是很简单的，但是具体实现起来就有很多的细节问题需要考虑周全，比如其中为了加快类的解析过程，使用了缓存。又比如使用了CGLIB来动态代理来实现方法注入。循环依赖的检测与处理，以及大量的反射技术。内容太多了，想要了解的透彻还得化很多时间去看源码。

说了那么多最终的收获在于了解了DI技术利弊，学了DI的编程思想。这种DI技巧并不总是在Java中才能实现的，而是每一种编程语言都有。并不是与Java的注解绑定的，注解只是简化了代码和提高了代码的可读性。其实我理解的DI最主要的思想就是让调用方不关心依赖类的创建逻辑和具体实现，调用方通过组装需要的依赖类来实现自己想要实现的逻辑。是一个高层依赖底层的一种关系。这种结构让大型多层应用能够有效的维护和开发，避免了牵一发而动全身的影响。

后序阅读更新（2019-12-25）

The Spring container validates the configuration of each bean as the container is created. However, the bean properties themselves are not set until the bean is actually created. Beans that are singleton-scoped and set to be pre-instantiated (the default) are created when the container is created. Scopes are defined in Bean Scopes. Otherwise, the bean is created only when it is requested. Creation of a bean potentially causes a graph of beans to be created, as the bean’s dependencies and its dependencies' dependencies (and so on) are created and assigned. Note that resolution mismatches among those dependencies may show up late — that is, on first creation of the affected bean.
//谷歌翻译
在创建容器时，Spring容器会验证每个bean的配置。但是，在实际创建Bean之前，不会设置Bean属性本身。创建容器时，将创建具有单例作用域并设置为预先实例化（默认）的Bean。范围在Bean范围中定义。否则，仅在请求时才创建Bean。创建和分配bean的依赖关系及其依赖关系（依此类推）时，创建bean可能会导致创建一个bean图。请注意，这些依赖项之间的分辨率不匹配可能会显示得较晚-即在首次创建受影响的bean时。


Reference


  The IoC Container

</p>
  
  <h2><a href="/2019/10/13/About-OAuth2.html">About OAuth2 </a></h2>
  <small>October 13, 2019</small>
  <p>Background

Recently,out team have to divided original system to two microservice system. let’s call they system A and system B.My goal is to implement a Authorization Server and Single-Sign-On. So i decided to use Spring security framework to do this.It’s not easy as i think,i got lots of problems.Finally i made it,and i want to recored this to review.

What is OAuth 2.0

OAuth is not an API or a service: it’s an open standard for authorization and anyone can implement it.OAuth 2.0 is widely used by applications.For example,a app need access your wechat contacts list,so the app need authorized by wechat,you have probably used OAuth 2.0.

OAuth 2.0 includes four roles:


  Resource owner (user’s private resources such as profile,photos etc)
  Client (the app want to access user’s resources)
  Resource server (stores user’s private resources and shares them with authorized clients)
  Authorization Server (used for certification)


OAuth 2.0 support four grant types to obtain the resource owner’s permission(called access_token)

  Password Credentials
  Client Credentials
  Authorization Code
  Implicit


Password Credentials usually used for trusted clients

  used by first-party clients to exchange a user’s credentials for an access token.


Client Credentials used to access resources owned by the client itself

  typically used by clients to access resources about themselves rather than to access a user’s resources.


Above two grant types will revealed resource owner’s credentials to third-part

Authorization Code the most complicate flow in OAuth 2.0

  used by confidential and public clients to exchange an authorization code for an access token.After the user returns to the client via the redirect URL, the application will get the authorization code from the URL and use it to request an access token.


Implicit generally not recommended to use the implicit flow

  a simplified flow that can be used by public clients, where the access token is returned immediately without an extra authorization code exchange step.


Above two grant type are more interesting as they are used by public clients and users give their permission to third party applications

In my practice,i only used Authorization Code and Password grant types , finally choose the Password grant type because own system A and system B is trusted clients.

Why using OAuth 2.0

Actually,i’m not sure why i have to using the OAuth 2.0.I just Google the Spring security want to make a Single-Sign-On system, and then the google search resutls show me lots of anwsers like : Spring Security SSO With OAuth 2.0 as far now i just know OAuth 2.0 is a protocolOAuth 2.0 is not an authentication protocol i have to use it if i using the Spring Security framework.So i’m thinking Why using OAuth 2.0? and Why OAuth 2.0 is safe?

i found a simple anwser of the What goal of the OAuth 2.0? on offical site.


  OAuth 2.0 focuses on client developer simplicity while providing specific authorization flows for web applications, desktop applications, mobile phones, and living room devices.


Simplicity is one of the keypoint for why using OAuth 2.0,becasue OAuth 1.0 implementation attempts are caused by the complexity of the cryptographic requirements of the specification.Anothrer reason is OAuth 2.0 support support for non-browser based applications.

OAuth 2.0 Access tokens are “short-lived” which means OAuth 2.0 is more safe than OAuth 2.0 , when access_token is expired you need refresh_token to get a new access_token.You should notice that access token can’t be revoked you just have to wait for them to time out.

Not interact with user credentials no need user’s username or password for access_token instead using authoirzation code exchange for access_token.

Keep user’s infomation in token It accesses the data using tokens instead of using their credentials and stores data in online file system of the user such as Google Docs or Dropbox account.

Conclusion

Actually,OAuth 2.0 purpose is to “How can I allow an app to access my data without necessarily giving it my password?” , and support non-browser based applications.OAuth 2.0 security depends on how you implement system is.

Reference


  Official Site
  Introducing OAuth 2.0
  What the Heck is OAuth?
  How is OAuth 2 different from OAuth 1?

</p>
  
  <h2><a href="/2019/09/17/Quarkus-Hot-Reload-With-IDEA.html">Quarkus Hot Reload With IDEA </a></h2>
  <small>September 17, 2019</small>
  <p>Quarkus


  A Kubernetes Native Java stack tailored for GraalVM &amp; OpenJDK HotSpot, crafted from the best of breed Java libraries and standards


For me ? quarkus is a standard  framework,it combine lots of useful web framework.And it provides amazing boot time and optimizes developer joy.Also it can compile to native app and support hot reload.YES,hot reload with IDEA is really awsome!when i found i can use IDEA deloyment Tools automatic upload file to a server machine and it will automic reload the server.Just like below picture say 👇:



It sounds easy but things not going well 😟.

First try

I configuraed the IDEA delopyment tool and upload the exmpale project to server machine.



execute cmd to start up :

  ./mvnw compile quarkus:dev


And everythins same to be fine :



But no matter how i modify the ExampleResource.java,it didn’t touch the hot reload.The ExampleResource.java did upload to the server machine.Why quarkus server not hot reload? So i using vim modify the ExampleResource.java on server machine,quarkus did hot reload.This is really confuse me.I’m wandering how’s the quarkus hot reload works ? Maybe i can found why IDEA automatic upload not trigger the hot reload.

Second Try

I notice that when i modify a file and only when i vistied the resource path on borwer quarkus would do hot reload.So i debug on the IDEA and watching what happend.

First i found the restart code (DevModMain.java) on github:

public synchronized void restartApp(Set&lt;String&gt; changedResources) {
        stop();
        Timing.restart();
        doStart(true, changedResources);
    }


And keep digging :

RuntimeUpdatesProcessor.java
@Override
    public boolean doScan(boolean userInitiated) throws IOException {
        final long startNanoseconds = System.nanoTime();
        for (Runnable step : preScanSteps) {
            try {
                step.run();
            } catch (Throwable t) {
                log.error("Pre Scan step failed", t);
            }
        }
        //This is key point 
        boolean classChanged = checkForChangedClasses();
        Set&lt;String&gt; filesChanged = checkForFileChange();

       ...
    }


Finally i found key method on checkForChangedClasses().

RuntimeUpdatesProcessor.java

 boolean checkForChangedClasses() throws IOException {
        boolean hasChanges = false;
        for (DevModeContext.ModuleInfo module : context.getModules()) {
            final List&lt;Path&gt; moduleChangedSourceFilePaths = new ArrayList&lt;&gt;();
            for (String sourcePath : module.getSourcePaths()) {
                final Set&lt;File&gt; changedSourceFiles;
                try (final Stream&lt;Path&gt; sourcesStream = Files.walk(Paths.get(sourcePath))) {
                    changedSourceFiles = sourcesStream
                            .parallel()
                            .filter(p -&gt; matchingHandledExtension(p).isPresent() &amp;&amp; wasRecentlyModified(p))
                            .map(Path::toFile)
                            //Needing a concurrent Set, not many standard options:
                            .collect(Collectors.toCollection(ConcurrentSkipListSet::new));
                }
                ...
    }


wasRecentlyModified(p)
    private boolean wasRecentlyModified(final Path p) {
        try {
            long sourceMod = Files.getLastModifiedTime(p).toMillis();
            return sourceMod &gt; lastChange;
        } catch (IOException e) {
            throw new RuntimeException(e);
        }
    }


quarkus hot reload depends on compare file last modified time with system last change time. the whole process is : when i send http request,quarkus will handle the request and check the resource file whether to modify and do hot reload.

So i change the IDEA config like this :



Enjoying Coding with quarkus 👏!
</p>
  
</div>



<!-- pagination -->

<div class="pagination">
  
  <span>&laquo; Prev</span>
  

  
  
  <span class="webjeda">1</span>
  
  
  
  <a href="/page2">2</a>
  
  

  
  <a href="/page2">Next &raquo;</a>
  
</div>

            </article>
        </main>

        <footer>
            <p class="copy">
                <small>Copyrights by
                    Joe
                    | Developed by
                    <a href="http://webjeda.com">webjeda</a>
                </small>
            </p>
        </footer>
        <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-157580785-1"></script>
<script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'UA-157580785-1');
</script>
    </body>

</html>
