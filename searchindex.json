{"categories":[{"title":"database","uri":"https://holicc.github.io/categories/database/"},{"title":"mysql","uri":"https://holicc.github.io/categories/mysql/"},{"title":"programing","uri":"https://holicc.github.io/categories/programing/"},{"title":"protocol","uri":"https://holicc.github.io/categories/protocol/"},{"title":"rocketMQ","uri":"https://holicc.github.io/categories/rocketmq/"},{"title":"system-design","uri":"https://holicc.github.io/categories/system-design/"},{"title":"windows","uri":"https://holicc.github.io/categories/windows/"}],"posts":[{"content":"Contents  Vertical scaling Horizontal scaling Caching Load balancing Database replication Database partitioning CAP theorem Domain name system Content delivery network  Vertical scaling Vertical scaling means add more new resources in the existing system to meet the expectation. In other words that you scale by adding more power (CPU, RAM) to an existing machine.\nGood example of vertical scaling is The cloud version of MySQL\nHorizontal scaling Horizontal scaling means that you scale by adding more machines. When added new resources to the existing system can't meet the expectation,we need to add completely new servers and distraction our services to these machines.\nGood examples of horizontal scaling are Cassandra, MongoDB\nCaching Caching means temporary storage location,usually store in RAM.So that they can be accessed more quickly.\nCached Database Queries That’s still the most commonly used caching pattern. Whenever you do a query to your database, you store the result dataset in cache. A hashed version of your query is the cache key. The next time you run the query, you first check if it is already in the cache. The next time you run the query, you check at first the cache if there is already a result. This pattern has several issues. The main issue is the expiration. It is hard to delete a cached result when you cache a complex query (who has not?). When one piece of data changes (for example a table cell) you need to delete all cached queries who may include that table cell. You get the point?  Load balancing In computing, **load balancing** refers to the process of distributing a set of tasks over a set of resources (computing units), with the aim of making their overall processing more efficient. Load balancing techniques can optimize the response time for each task, avoiding unevenly overloading compute nodes while other compute nodes are left idle.  more\nDatabase replication Database replication can be used on many database management systems (DBMS), usually with a master-slave relationship between the original and the copies. The master logs the updates, which then ripple through to the slaves. Each slave outputs a message stating that it has received the update successfully, thus allowing the sending of subsequent updates.  more\nkeywords: master-slave relationship,multi-master replication,distributed transaction\nDatabase replication becomes more complex when it scales up horizontally and vertically. Horizontal scale-up has more data replicas, while vertical scale-up has data replicas located at greater physical distances. Problems raised by horizontal scale-up can be alleviated by a multi-layer, multi-view access protocol. The early problems of vertical scale-up have largely been addressed by improving Internet reliability and performance.  Database partitioning A partition is a division of a logical database or its constituent elements into distinct independent parts. Database partitioning is normally done for manageability, performance or availability[1] reasons, or for load balancing. It is popular in distributed database management systems, where each partition may be spread over multiple nodes, with users at the node performing local transactions on the partition. This increases performance for sites that have regular transactions involving certain views of data, whilst maintaining availability and security.  more eg: ElasticSearch\nCAP theorem Dr. Eric Brewer gave a keynote speech at the Principles of Distributed Computing conference in 2000 called 'Towards Robust Distributed Systems' [1]. In it he posed his 'CAP Theorem' - at the time unproven - which illustrated the tensions between being correct and being always available in distributed systems. Two years later, Seth Gilbert and Professor Nancy Lynch - researchers in distributed systems at MIT - formalised and proved the conjecture in their paper “Brewer's conjecture and the feasibility of consistent, available, partition-tolerant web services” [2].   Consistency - Every read receives the most recent write or an error Availability - Every request receives a response, without guarantee that it contains the most recent version of the information Partition Tolerance - The system continues to operate despite arbitrary partitioning due to network failures  CP - consistency and partition tolerance Waiting for a response from the partitioned node might result in a timeout error. CP is a good choice if your business needs require atomic reads and writes.  AP - availability and partition tolerance Responses return the most readily available version of the data available on any node, which might not be the latest. Writes might take some time to propagate when the partition is resolved. AP is a good choice if the business needs allow for eventual consistency or when the system needs to continue working despite external errors.  Domain name system DNS is hierarchical, with a few authoritative servers at the top level. Your router or ISP provides information about which DNS server(s) to contact when doing a lookup. Lower level DNS servers cache mappings, which could become stale due to DNS propagation delays. DNS results can also be cached by your browser or OS for a certain period of time, determined by the time to live (TTL).  more\nContent delivery network A CDN helps to speed up static components of your blog (especially pictures of say, your bed in Rome) by distributing them across a number of servers around the world. This does two things – one is to put much of your travel blog’s content closer to the person who wants to view it. So, a person in Japan will download your beautiful photos of Granada from Tokyo, rather than your server sitting in Boston, for example. Less distance traveled means a faster download and secondly, if the content isn’t being pulled directly from your server, it saves overall computing power (important to have plenty of for when traffic gets really busy).  Serving content from CDNs can significantly improve performance in two ways:\n- Users receive content from data centers close to them - Your servers do not have to serve requests that the CDN fulfills  Materials  Paxos算法 Raft 拜占庭将军问题  ","id":0,"section":"posts","summary":"Contents Vertical scaling Horizontal scaling Caching Load balancing Database replication Database partitioning CAP theorem Domain name system Content delivery network Vertical scaling Vertical scaling means add more new resources in the existing system to meet the expectation. In other words that you scale by adding more power (CPU, RAM) to an existing machine. Good example of vertical scaling is The cloud version of MySQL Horizontal scaling Horizontal scaling means that","tags":["system-design"],"title":"Common Principles","uri":"https://holicc.github.io/2020/10/principles/","year":"2020"},{"content":"Intro Recently,I'm interested in HTTP-Range-Download. So i decided build a toy with Rust\nReference  Go实现 HTTP 请求方法  ","id":1,"section":"posts","summary":"Intro Recently,I'm interested in HTTP-Range-Download. So i decided build a toy with Rust Reference Go实现 HTTP 请求方法","tags":["http","rust"],"title":"HTTP Range Download","uri":"https://holicc.github.io/2020/09/http-range/","year":"2020"},{"content":"[Copy]Logout: GET or POST  This question is not about when to use GET or POST in general; it is about which is the recommended one for handling logging out of a web application. I have found plenty of information on the differences between GET and POST in the general sense, but I did not find a definite answer for this particular scenario.\nAs a pragmatist, I'm inclined to use GET, because implementing it is way simpler than POST; just drop a simple link and you're done. This seems to be case with the vast majority of websites I can think of, at least from the top of my head. Even Stack Overflow handles logging out with GET.\nThe thing making me hesitate is the (albeit old) argument that some web accelerators/proxies pre-cache pages by going and retrieving every link they find in the page, so the user gets a faster response when she clicks on them. I'm not sure if this still applies, but if this was the case, then in theory a user with one of these accelerators would get kicked out of the application as soon as she logs in, because her accelerator would find and retrieve the logout link even if she never clicked on it.\nEverything I have read so far suggest that POST should be used for \u0026quot;destructive actions\u0026quot;, whereas actions that do not alter the internal state of the application -like querying and such- should be handled with GET. Based on this, the real question here is:\nIs logging out of an application considered a destructive action/does it alter the internal state of the application?\n Answer  Use POST\nIn 2010, using GET was probably an acceptable answer. But today (in 2013), browsers will pre-fetch pages they \u0026quot;think\u0026quot; you will visit next.(浏览器的预加载机制可能会加载登出链接，可是我没遇到过啊！)\n ","id":2,"section":"posts","summary":"[Copy]Logout: GET or POST This question is not about when to use GET or POST in general; it is about which is the recommended one for handling logging out of a web application. I have found plenty of information on the differences between GET and POST in the general sense, but I did not find a definite answer for this particular scenario. As a pragmatist, I'm inclined to use GET,","tags":["web"],"title":"Logout GET or POST","uri":"https://holicc.github.io/2020/09/about-logout-method/","year":"2020"},{"content":"goroutine limiter var count int32 resp := make([]*CommandResponse, len(req.Images)) // waitForAllJob := make(chan struct{}, cfg.Server.MaxParallelNum) defer close(waitForAllJob) // for i := 0; i \u0026lt; len(req.Images); i++ { waitForAllJob \u0026lt;- struct{}{} go func(index int, img *model.Image) { response := process(img) resp[index] = response \u0026lt;-waitForAllJob atomic.AddInt32(\u0026amp;count, 1) }(i, \u0026amp;req.Images[i]) } // for int32(len(req.Images)) != count { }  ","id":3,"section":"posts","summary":"goroutine limiter var count int32 resp := make([]*CommandResponse, len(req.Images)) // waitForAllJob := make(chan struct{}, cfg.Server.MaxParallelNum) defer close(waitForAllJob) // for i := 0; i \u0026lt; len(req.Images); i++ { waitForAllJob \u0026lt;- struct{}{} go func(index int, img *model.Image) { response := process(img) resp[index] = response \u0026lt;-waitForAllJob atomic.AddInt32(\u0026amp;count, 1) }(i, \u0026amp;req.Images[i]) } // for int32(len(req.Images)) != count { }  ","tags":["programing"],"title":"Go Code Style","uri":"https://holicc.github.io/2020/09/go-code-snippet/","year":"2020"},{"content":"History POSTGRES的实现始于 1986 年，现在被称为PostgreSQL的对象-关系型数据库管理系统是从加州大学伯克利分校写的POSTGRES软件包发展而来的。经过二十多年的发展，PostgreSQL是世界上可以获得的最先进的开源数据库。\nAdvantage Postgres is an object-relational database, while MySQL is a purely relational database\nPostgres handles concurrency better than MySQL for multiple reasons:\n Postgres implements Multiversion Concurrency Control (MVCC) without read locks(不使用锁来实现MVCC机制) Postgres supports parallel query plans that can use multiple CPUs/cores(多核利用) Postgres can create indexes in a non-blocking way (through the CREATE INDEX CONCURRENTLY syntax), and it can create partial indexes (for example, if you have a model with soft deletes, you can create an index that ignores records marked as deleted) Postgres is known for protecting data integrity at the transaction level. This makes it less vulnerable to data corruption.(安全性)  Postgres is highly extensible. It supports a number of advanced data types not available in MySQL (geometric/GIS, network address types, JSONB which can be indexed, native UUID, timezone-aware timestamps). If this is not enough, you can also add your own data-types, operators, and index types.(支持更多的数据类型和支持自定义类型)\nDrawbacks  Postgres is still less popular than MySQL(为什么?) Postgres forks a new process for each new client connection which allocates a non-trivial amount of memory (about 10 MB).(MySQL好像是单线程的) Postgres is built with extensibility, standards compliance, scalability, and data integrity in mind - sometimes at the expense of speed. Therefore, for simple, read-heavy workflows, Postgres might be a worse choice than MySQL.(高级特性是有代价的)  Summary 简单了解后：性能上差不多,不需要根据性能的不同选择Postgres。更多的是因为Postgres拥有更多的拓展性。还有license。\n参考  mysql-vs-postgres mysql-vs-postgres PostgreSQL中文手册 PostgreSQL 与 MySQL 相比，优势何在？  ","id":4,"section":"posts","summary":"History POSTGRES的实现始于 1986 年，现在被称为PostgreSQL的对象-关系型数据库管理系统是从加州大学伯克利分校写的POSTGRES软件包","tags":["database"],"title":"Postgres VS MySQL","uri":"https://holicc.github.io/2020/08/postgres/","year":"2020"},{"content":"Receiver Type Choosing whether to use a value or pointer receiver on methods can be difficult, especially to new Go programmers. If in doubt, use a pointer, but there are times when a value receiver makes sense, usually for reasons of efficiency, such as for small unchanging structs or values of basic type. Some useful guidelines:\n If the receiver is a map, func or chan, don't use a pointer to them. If the receiver is a slice and the method doesn't reslice or reallocate the slice, don't use a pointer to it. If the method needs to mutate the receiver, the receiver must be a pointer. If the receiver is a struct that contains a sync.Mutex or similar synchronizing field, the receiver must be a pointer to avoid copying. If the receiver is a large struct or array, a pointer receiver is more efficient. How large is large? Assume it's equivalent to passing all its elements as arguments to the method. If that feels too large, it's also too large for the receiver. Can function or methods, either concurrently or when called from this method, be mutating the receiver? A value type creates a copy of the receiver when the method is invoked, so outside updates will not be applied to this receiver. If changes must be visible in the original receiver, the receiver must be a pointer. If the receiver is a struct, array or slice and any of its elements is a pointer to something that might be mutating, prefer a pointer receiver, as it will make the intention more clear to the reader. If the receiver is a small array or struct that is naturally a value type (for instance, something like the time.Time type), with no mutable fields and no pointers, or is just a simple basic type such as int or string, a value receiver makes sense. A value receiver can reduce the amount of garbage that can be generated; if a value is passed to a value method, an on-stack copy can be used instead of allocating on the heap. (The compiler tries to be smart about avoiding this allocation, but it can't always succeed.) Don't choose a value receiver type for this reason without profiling first. Finally, when in doubt, use a pointer receiver.  type User struct { Name string Age int } func NewUser(name string, age int) *User { return \u0026amp;User{ Name: name, Age: age, } }  Return a pointer rather than a struct to void data copy !\n","id":5,"section":"posts","summary":"Receiver Type Choosing whether to use a value or pointer receiver on methods can be difficult, especially to new Go programmers. If in doubt, use a pointer, but there are times when a value receiver makes sense, usually for reasons of efficiency, such as for small unchanging structs or values of basic type. Some useful guidelines:\n If the receiver is a map, func or chan, don't use a pointer to them.","tags":["programing"],"title":"Go Code Style","uri":"https://holicc.github.io/2020/08/go-code-style/","year":"2020"},{"content":"Unix时间戳：\nGet-Date -UFormat %s  查看文件（类似cat的功能）\ntype $file  创建文件：\nNew-Item [path]  使用记事本打开文件\nStart-Process notepad $file  打开文件夹\nii .  或者\nInvoke-Item .  函数别名\nSet-Alias  如何配置PowerShell Profile\n","id":6,"section":"posts","summary":"Unix时间戳： Get-Date -UFormat %s 查看文件（类似cat的功能） type $file 创建文件： New-Item [path] 使用记事本打开文件 Start-Process notepad $file 打开文件夹 ii . 或者 Invoke-Item . 函数别名 Set-Alias 如何配置Powe","tags":["powershell"],"title":"Powershell Notes","uri":"https://holicc.github.io/2020/08/powershell-notes/","year":"2020"},{"content":"RocketMQ服务部署情况介绍 由于项目对消息的可靠性要求比较高所以采用的是SYNC_MASTER+SLAVE的部署方式, 并且使用了ASYNC_FLUSH（同步刷新）机制，虽然Master节点宕机的时候会丢失一部分的消息数据，但是性能上是很大的提升；\n根据官方说明的优缺点：\n 优点：数据与服务都无单点故障，Master宕机情况下，消息无延迟，服务可用性与数据可用性都非常高； 缺点：性能比异步复制模式略低（大约低10%左右），发送单个消息的RT会略高，且目前版本在主节点宕机后，备机不能自动切换为主机（针对4.5以前的版本）。  由于我们使用的是4.7.0版本已经使用了raft 协议解决了这个问题。如果要使集群能够自动容灾切换，需要至少三台机器\n我们一共有4台机器，每台机器的配置：\n32g内存，2T的硬盘，8核CPU  一台机器作为nameserver，其余都是broker，broker之间可以进行自动选举master节点\n部署情况：\n\n配置文件编写情况：\n#所属集群名字 brokerClusterName=RaftCluster brokerName=RaftNode00 ## 启用DLeger enableDLegerCommitLog=true dLegerGroup=RaftNode00 dLegerPeers=n0-127.0.0.1:40911;n1-127.0.0.1:40912;n2-127.0.0.1:40913 dLegerSelfId=n0 #0 表示 Master，\u0026gt;0 表示 Slave brokerId=0 #nameServer地址，分号分割 namesrvAddr=rocketmq-nameserver-0:9876 autoCreateTopicEnable=false autoCreateSubscriptionGroup=false #Broker 对外服务的监听端口，10911为默认值 listenPort=10911 #表示Master监听Slave请求的端口,默认为服务端口+1 haListenPort=10912 #- SLAVE brokerRole=ASYNC_MASTER #刷盘方式 flushDiskType=ASYNC_FLUSH  RocketMQ消费端设置情况 Consumer使用的是公司封装的所以能够配置的参数有限，通过阅读封装的代码发现，\nconsumeMessageBatchMaxSize=10一批次可以处理10条数据 setConsumeThreadMin=3后面修改为了CPU核心数 setConsumeThreadMax=3后面修改为了CPU核心数 setMessageModel=MessageModel.CLUSTERING 集群模式 setConsumeFromWhere=ConsumeFromWhere.CONSUME_FROM_LAST_OFFSET 接着上次消费的进度开始消费\n其余的参数都没有进行改动\nRocketMQ消息堆积了如何解决 原因：消费服务太慢导致消息堆积；\n这里的堆积指的是Consumer拉取的消息消费不过来了导致的堆积\n我们的系统中使用的是PUSH的消费模式，本质上是使用PULL不断的向Broker拉取消息机制的封装。\n解决办法：\n 先修复 consumer 的问题，确保其恢复消费速度，然后将现有 consumer 都停掉。（因为历史数据积压太多，短时间内无法消费完） 建立新的topic，临时建立好原先 10 倍的 queue 数量。 然后写一个临时的分发数据的 consumer 程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的 10 倍数量的 queue 接着临时征扩容机器机器来部署 consumer，每一批 consumer 消费一个临时 queue 的数据。 等快速消费完积压数据之后，得恢复原先部署的架构，重新用原先的 consumer 机器来消费消息。  ","id":7,"section":"posts","summary":"RocketMQ服务部署情况介绍 由于项目对消息的可靠性要求比较高所以采用的是SYNC_MASTER+SLAVE的部署方式, 并且使用了ASYN","tags":["programing","rocketMQ"],"title":"RocketMQ","uri":"https://holicc.github.io/2020/07/rocketmq-overstock/","year":"2020"},{"content":"索引是什么 索引（在MySQL中也称为“键（key）”），用于存储引擎快速找到记录的一种数据结构。这是索引的基础功能。 索引可以包含一个列或多个列，当索引包含多个列的时候，那么列的顺序也十分重要，因为MySQL只能使用最左前缀列。\n索引的目的  索引大大减少了服务器扫描的数据量 帮助服务器避免排序和临时表 索引可以将随机I/O变为顺序I/O  索引的种类 在MySQL中，索引是由存储引擎实现的而不是由服务层实现的，所以并没有同一的标准：不同存储引擎的索引工作方式并不一样，也不是所有的存储引擎都支持所有类型的索引。即时多个存储引擎支持同种索引，其底层实现也可能不同。\nB-Tree索引 B-Tree是为磁盘等外存储设备设计的一种平衡查找树。因此在讲B-Tree之前先了解下磁盘的相关知识。\n系统从磁盘读取数据到内存时是以磁盘块（block）为基本单位的，位于同一个磁盘块中的数据会被一次性读取出来，而不是需要什么取什么。\nInnoDB存储引擎中有 页（Page） 的概念，页是其磁盘管理的最小单位。InnoDB存储引擎中默认每个页的大小为16KB，可通过参数innodb_page_size将页的大小设置为4K、8K、16K，在MySQL中可通过如下命令查看页的大小：\n show variables like 'innodb_page_size';\n 而系统一个磁盘块的存储空间往往没有这么大，因此InnoDB每次申请磁盘空间时都会是若干地址连续磁盘块来达到页的大小16KB。InnoDB在把磁盘数据读入到磁盘时会以页为基本单位，在查询数据时如果一个页中的每条数据都能有助于定位数据记录的位置，这将会减少磁盘I/O次数，提高查询效率。\nB-Tree结构的数据可以让系统高效的找到数据所在的磁盘块。为了描述B-Tree，首先定义一条记录为一个二元组[key, data] ，key为记录的键值，对应表中的主键值，data为一行记录中除主键外的数据。对于不同的记录，key值互不相同。\n\n每个节点占用一个盘块的磁盘空间，一个节点上有两个升序排序的关键字和三个指向子树根节点的指针，指针存储的是子节点所在磁盘块的地址。两个关键词划分成的三个范围域对应三个指针指向的子树的数据的范围域。以根节点为例，关键字为17和35，P1指针指向的子树的数据范围为小于17，P2指针指向的子树的数据范围为17~35，P3指针指向的子树的数据范围为大于35。\nB+Tree索引 从B-Tree结构图中可以看到每个节点中不仅包含数据的key值，还有data值。而每一个页的存储空间是有限的，如果data数据较大时将会导致每个节点（即一个页）能存储的key的数量很小，当存储的数据量很大时同样会导致B-Tree的深度较大，增大查询时的磁盘I/O次数，进而影响查询效率。在B+Tree中，所有数据记录节点都是按照键值大小顺序存放在同一层的叶子节点上，而非叶子节点上只存储key值信息，这样可以大大加大每个节点存储的key值数量，降低B+Tree的高度。\n由于B+Tree的非叶子节点只存储键值信息，假设每个磁盘块能存储4个键值及指针信息，则变成B+Tree后其结构如下图所示：\n\n适用条件：\n 全值匹配 匹配最左前缀 匹配范围值 精确匹配某一列并范围匹配另一列 值访问索引的查询  限制：\n 如果不是按照索引的最左列开始查找，则无法使用索引 不能跳过索引中的列 如果查询中有某个列的范围查询，则其右边所有列都无法使用索引优化查找  Hash索引 哈希索引（hash index）基于哈希表实现，只有精确匹配索引所有列的查询才有效，对于每一行数据，存储引擎都会对所有的索引列计算一个哈希值，哈希值是一个较小的值，并不同的键值的行计算的哈希值也不一样。哈希索引将所有的哈希值存储在索引中，同时在哈希表中保存指向每个数据行的指针。\n限制：\n 哈希索引只包含哈希值和行指针，不存储字段值，所以不能使用索引中的字段避免读取行 哈希索引数据无法用于排序 不支持索引列匹配查找，例如，在数据列（A，B）上建立的索引，如果查询只用到列A列则无法使用该索引 哈希索引只支持等值比较查询 哈希冲突太多会导致性能很低  InnoDB中有一个特殊的功能叫做“自适应索引”InnoDB会注意到使用非常频繁的索引值，会在内存中基于B-Tree索引之上再创建一个哈希索引。\n如何正确的使用索引 独立的列 “独立的列”是指索引列不能是表达式的一部分，也不能是函数的参数。\n例如：\n mysql\u0026gt; SELECT actor_id from actors where actor_id +1 =5 ;\n 这个例子就无法使用索引列 actor_id 。所以在使用WHERE条件的时候，始终将索引列单独放在比较符号的一侧，也不能对索引列使用函数。\n前缀索引和索引选择性 由于需要索引列是一个很长的字符串，这样会导致索引边的慢且大。这时可以通过使用前缀索引来解决，这样可以大大节约索引空间，从而提高索引效率。但是这样会降低索引的选择性。\n 选择性=补充度的索引值(基数)/数据表的记录时总数\n 索引的选择性越高则查询效率越高，唯一索引的选择性是1，这时最好的索引选择性，性能也是最好的。\n多列索引 在多个列上建立独立的单列索引大部分情况下并不能提高MySQL的查询性能。新版本的MySQL中引入了一种叫“索引合并”的策略\n聚簇索引 聚族索引并不是一种单独的索引类型，而是一种数据存储方式。InnoDB聚族索引实际上在同一个结构中保存了B-Tree索引和数据行\n聚簇索引就是按照每张表的主键构造一颗B+树，同时叶子节点中存放的就是整张表的行记录数据，也将聚集索引的叶子节点称为数据页。这个特性决定了索引组织表中数据也是索引的一部分，每张表只能拥有一个聚簇索引。\n聚簇索引的每一个叶节点都包含了主键值、 事务ID、 用于事务和MVCC的回滚指针、以及剩余的列\n\nInnodb通过主键聚集数据，如果没有定义主键，innodb会选择非空的唯一索引代替。如果没有这样的索引，innodb会隐式的定义一个主键来作为聚簇索引。\n聚簇索引的优缺点\n 优点：  数据访问更快，因为聚簇索引将索引和数据保存在同一个B+树中，因此从聚簇索引中获取数据比非聚簇索引更快 聚簇索引对于主键的排序查找和范围查找速度非常快 使用 覆盖索引 扫描的查询可以直接使用页节点中的主键值  缺点：  插入速度严重依赖于插入顺序，按照主键的顺序插入是最快的方式，否则将会出现页分裂，严重影响性能(例如：使用UUID作为索引，它会使插入边的完全随机就会造成页分裂和产生随机碎片)。因此，对于InnoDB表，我们一般都会定义一个自增的ID列为主键 更新主键的代价很高，因为将会导致被更新的行移动。因此，对于InnoDB表，我们一般定义主键为不可更新。 二级索引访问需要两次索引查找，第一次找到主键值，第二次根据主键值找到行数据。 聚簇索引可能导致全表扫描变慢，尤其是行比较稀疏，或者由于 页分裂 导致数据存储不连续的时候   辅助索引（非聚簇索引） 在聚簇索引之上创建的索引称之为辅助索引，辅助索引访问数据总是需要二次查找。辅助索引叶子节点存储的不再是行的物理位置，而是主键值。通过辅助索引首先找到的是主键值，再通过主键值找到数据行的数据页，再通过数据页中的Page Directory找到数据行。\nInnodb辅助索引的叶子节点并不包含行记录的全部数据，叶子节点除了包含键值外，还包含了相应行数据的聚簇索引键。这样的策略减少了当出现行移动或者数据页分裂时二级索引的维护工作。使用主键当作指针会让二级索引占用更多的空间，换来的好处是，InnoDB在移动行时无须更新二级索引中的这个“指针”\n辅助索引的存在不影响数据在聚簇索引中的组织，所以一张表可以有多个辅助索引。在innodb中有时也称辅助索引为二级索引。\n\n与MyISAM引擎中索引的区别如下图：\n\n覆盖索引 如果一个索引包含（或者说是覆盖）所有需要查询的字段的值，我们就称之为“覆盖索引”，覆盖索引的优点本质上就一条：覆盖索引能够避免 *回表*；\n不是所有类型的索引都可以称为覆盖所有。覆盖所有必须要存储索引列的值，而哈希索引、空间索引和全文索引等都不存储索引列的值，所以MySQL只能使用B-Tree索引做覆盖索引。\n当发起一个被索引覆盖的查询（也叫做索引覆盖查询）时，在EXPLAIN的Extra列可以看到“Using index”的信息\nMySQL查询优化器会在执行查询前判断是否有一个索引能够进行覆盖\n参考  聚簇索引和非聚簇索引(通俗易懂 言简意赅) Mysql 索引  ","id":8,"section":"posts","summary":"索引是什么 索引（在MySQL中也称为“键（key）”），用于存储引擎快速找到记录的一种数据结构。这是索引的基础功能。 索引可以包含一个列或多个","tags":["index","mysql"],"title":"MySQL 索引","uri":"https://holicc.github.io/2020/03/about-mysql-index/","year":"2020"},{"content":"TCP是什么 ? 传输控制协议（TCP）是互联网协议组中重要的组成部分之一。TCP的实现之初是为了补充互联网协议（IP）。因此，这一对组合经常被称为TCP/IP。TCP协议的特点：可靠性、顺序性、错误检查、数据流传输。大部分常见的应用都是使用的是TCP协议，例如：World Wide Web、Email、文件传输.TCP是面向连接的，这就需要客户端主动与服务端建立起连接之后才能开始传输数据。如果应用不需要可靠的数据流传输服务可能UPD协议是个更好的选择。\n为什么需要TCP ? TCP是个重要的协议是因为它在互联网的基础上建立了一套规则与标准化的信息数据传输机制。TCP让互联网之间的数据传输能够无视各种条件的限制（不管是地区限制、软件或硬件的限制），并且它是灵活的可拓展的（比如TCP/IP、增加SSL等），并且它是开源的不是私人所有。\n如何保证传输的可靠性? TCP segment structure TCP报文段分为两段：报头、数据段。报头包含10个字段和一个可选的拓展字段。数据段紧跟在 报头后面，里面装的都是应用传输的数据。数据的大小（length）不包括在 报头中；但是可以通过IP数据报的报头中指定的长度减去TCP报头的长度就得到了数据段的大小了。\n\n源端口(16 bits) \u0026amp; 目的端口(16 bits) 本机端口和目的地端口\n序列号(32 bits) 序列号就是用来标记每一个请求的，相当于请求的ID。\n 如果含有同步标识（SYN），则此为最初的序列号；第一个数据比特的序列码为本序列号加一 如果没有同步标识（SYN），则此为第一个数据比特的序列码  确认号 (32 bits) ACK如果被启用了，那么表示收到信息，并且ACK=（发送者的序列号+1）用于验证。\n连接建立 TCP连接的建立需要进行三次握手。在客户端尝试连接服务端之前，服务端需要绑定一个端口并监听它（passive open），之后客户端会主动向服务端发送建立连接请求，并进行 三次握手 建立连接。\n1.客户端向服务端发起一个 SYN请求，并将生成一个随机的序列号A。\n2.作为响应，服务端回复带有SYN-ACK标示的应答。其中ACK=A+1，并同时生成一个随机序列号B。\n3.最后，客户端收到服务端的ACK应答之后。客户端又会给服务端一个ACK应答并且序列号也会加一也A+1，然后ACK的序列号也加一B+1\n到这时候，客户端和服务端都收到了确认连接的消息。步骤1、2建立一个方向的连接参数(序列号)并确认。步骤2、3建立另一个方向的连接参数(序列号)并确认。有了这些，就可以建立全双工通信。\n\nTCP 连接使用三次握手的首要原因：为了 阻止历史的重复连接初始化造成的混乱问题。如果通信双方的通信次数只有两次，那么发送方一旦发出建立连接的请求之后它就没有办法撤回这一次请求，如果在网络状况复杂或者较差的网络中，发送方连续发送多次建立连接的请求，如果 TCP 建立连接只能通信两次，那么接收方只能选择接受或者拒绝发送方发起的请求，它并不清楚这一次请求是不是由于网络拥堵而早早过期的连接。\n所以，TCP 选择使用三次握手来建立连接并在连接引入了 RST 这一控制消息，接收方当收到请求时会将发送方发来的 SEQ+1 发送给对方，这时由发送方来判断当前连接是否是历史连接：\n如果当前连接是历史连接，即 SEQ 过期或者超时，那么发送方就会直接发送 RST 控制消息中止这一次连接； 如果当前连接不是历史连接，那么发送方就会发送 ACK 控制消息，通信双方就会成功建立连接； 使用三次握手和 RST 控制消息将是否建立连接的最终控制权交给了发送方，因为只有发送方有足够的上下文来判断当前连接是否是错误的或者过期的，这也是 TCP 使用三次握手建立连接的最主要原因。\n连接终止 TCP连接的关闭需要进行 四次挥手，两边都需要关闭连接，整个TCP连接才算完整的关闭。希望关闭连接，就会传送 FIN 包并包含之前的ACK包。所以关闭连接需要 一组 FIN 和 ACK。当一边的发送了第一个 FIN和最后的 ACK，会进入一个等待超时状态 TIME_WATI 之道整个连接关闭，在整个连接关闭之前TCP占用的端口不能被其他新连接所使用；这防止了由于延迟发包带来的混乱问题。\n\n对于复杂的网络状态，TCP 的实现提出了多种应对措施， TIME_WAIT 状态的提出就是为了应对其中一种异常状况。在 TIME_WAIT 阶段，主动端等待 2*MSL（最大分段寿命：表示一个 TCP 分段可以存在于互联网系统中的最大时间，由 TCP 的实现，超出这个寿命的分片都会被丢弃） 时间， MSL 建议为 2 分钟。\n如果没有 TIME_WAIT 状态，Client 不再保存这个连接的信息，收到一个不存在的连接的包，Client 会响应 RST 包，导致 Server 端异常响应。此时， TIME_WAIT 是为了 保证全双工的 TCP 连接正常终止。\n如果双方挥手之后，一个 网络四元组（src/dst ip/port）被回收，而此时网络中还有一个迟到的数据包没有被 Server 接收，Client 应用程序又立刻使用了同样的四元组再创建了一个新的连接后，这个迟到的数据包才到达 Server，那么这个数据包就会让 Server 以为是 Client 刚发过来的。此时， TIME_WAIT 的存在是为了 保证网络中迷失的数据包正常过期。\n连接可以处于半开状态，意思就是TCP的有一方连接已经关闭了，另一方还没有关闭。\n\n数据传输 可靠性传输 TCP使用 序列号标记每一份数据，通过使用序号和确认号，TCP 层可以把收到的报文段中的字节按正确的顺序交付给应用层，TCP 协议使用序号标识每端发出的字节的顺序，从而另一端接收数据时可以重建顺序，无惧传输时的包的乱序交付或丢包。在发送第一个包时（SYN包），选择一个 随机数 作为序号的初值，以克制 TCP 序号预测攻击。\n发送确认包（Acks），携带了接收到的对方发来的字节流的编号，称为确认号，以告诉对方 已经成功接收的数据流的字节位置。Ack并不意味着数据已经交付了上层应用程序。可\n靠性通过发送方检测到丢失的传输数据并重传这些数据。包括 超时重传（Retransmission timeout，RTO）与 重复累计确认 （duplicate cumulative acknowledgements，DupAcks）。\n重复累计确认重传 如果一个包（不妨设它的序号是 100 ，即该包始于第 100 字节）丢失，接收方就不能确认这个包及其以后的包，因为采用了 累计ACK 。接收方在收到 100 以后的包时，发出对包含第 99 字节的包的确认。这种重复确认是包丢失的信号。发送方如果收到 3 次对同一个包的确认，就重传最后一个未被确认的包。阈值设为 3 被证实可以减少乱序包导致的无作用的重传（spurious retransmission）现象。选择性确认（SACK）的使用能明确反馈哪个包收到了，极大改善了TCP重传必要的包的能力。\n超时重传 发送方使用一个保守估计的时间作为收到数据包的确认的超时上限。如果超过这个上限仍未收到确认包，发送方将重传这个数据包。每当发送方收到确认包后，会重置这个重传定时器。典型地，定时器的值设定为 \\({\\displaystyle {\\text{smoothed RTT}}+\\max(G,4\\times {\\text{RTT variation}})}\\) 是时钟粒度。进一步，如果重传定时器被触发，仍然没有收到确认包，定时器的值将被设为前次值的二倍（直到特定阈值）。这可对抗 中间人攻击方式的拒绝服务攻击，这种攻击愚弄发送者重传很多次导致接受者被压垮。\n流量控制 流量控制用来避免主机分组发送得过快而使接收方来不及完全收下，一般由接收方通告给发送方进行调控，这里的窗口被称为 接收通知窗口（Receiver's Advertised Window）。\n流量控制通过 滑动窗口机制 来实现： 报文发送方 在 WIN 域指出还可接收的字节数量（rwnd）。报文接收方在没有新的确认包的情况下至多发送 WIN 允许的字节数量。在数据传输过程中，报文发送方可修改 WIN 的值。\n拥塞控制 TCP 拥塞控制算法是互联网上主要的拥塞控制措施，它使用一套基于 线増积减（Additive increase/multiplicative decrease，AIMD）的网络拥塞控制方法来控制拥塞，防止过多的数据注入到网络中，这样可以使网络中的路由器或链路不致过载。\n除了 拥塞窗口大小（cwnd） 之外，TCP 连接的双方都有 接收窗口大小（rwnd）。客户端能够同时传输的最大数据段的数量是接收窗口大小和拥塞窗口大小的最小值，即 min(rwnd, cwnd)min(rwnd,cwnd) 。\nTCP 协议使用慢启动阈值（Slow start threshold, ssthresh）来决定使用慢启动或者拥塞避免算法：\n当拥塞窗口大小小于慢启动阈值时，使用慢启动； 当拥塞窗口大小大于慢启动阈值时，使用拥塞避免算法； 当拥塞窗口大小等于慢启动阈值时，使用慢启动或者拥塞避免算法；\n慢开始和拥塞避免 客户端维持一个 拥塞窗口 cwnd 的状态变量，初始值一般为 2\\times MSS2×MSS 。\n 慢开始：由小到大的指数增大拥塞窗口。首先将 cwnd 设置为一个最大报文段 MMS ，在收到一个对新的报文段的确认后，把拥塞窗口增加一个 MMS 。\n 拥塞避免：当慢开始到阈值（ssthresh）后，使用拥塞避免算法（ cwnd 每次加1 ）。当发送方发送的数据包丢包时，将 ssthresh 置为 cwnd 的一半，将 cwnd 置为1，再次执行慢开始。\n  快重传和快恢复 快速重传和恢复（fast retransmit and recovery，FRR） 是一种拥塞控制算法，它能快速恢复丢失的数据包。没有 FRR，如果数据包丢失了，TCP 将会使用定时器来要求传输暂停。在暂停的这段时间内，没有新的或复制的数据包被发送。有了FRR，如果接收机接收到一个不按顺序的数据段，它会立即给客户端发送一个重复确认。如果客户端接收到三个重复确认，它会认定数据段丢失，并立即重传这些丢失的数据段。\n有了 FRR，就不会因为重传时要求的暂停被耽误。当有单独的数据包丢失时，快速重传和恢复（FRR）能最有效地工作。当有多个数据信息包在某一段很短的时间内丢失时，它则不能很有效地工作。\nBBR BBR（Bottleneck Bandwidth and Round-trip propagation time）是 Google 研发的新的拥塞控制算法。自从 20 世纪 80年代后， TCP 中的拥塞控制算法都使用的是 基于丢包的拥塞控制（拥塞避免），在之前的网络带宽、路由器 Buffer 的情况下，该算法效果良好。\n但是在当前的网络条件下，基于丢包的拥塞控制算法则会导致 TCP 性能问题：\n在小 Buffer 路由器环境下，丢包发生在拥塞之前。在高速，长途链路中，基于丢包的拥塞控制会导致吞吐量过低，因为它反应过度，即使丢包是由瞬时流量突发引起的，也会因丢包而将发送速率减半（即使链路大部分处于空闲状态，这种丢包也可能非常频繁） 在大 Buffer 路由器环境下，拥塞发生在丢包之前。在互联网的边缘，基于丢包的拥塞控制通过反复填充大量的缓存，从而导致了臭名昭著的 bufferbloat 问题。 bufferbloat 问题：由于路由器的大缓存，减少链路丢包。再加上网络中 TCP 大量使用基于丢包的拥塞控制算法（丢包才触发速度下调，但是要丢包，缓存就得先被填满，缓存都填满，延迟更高）\nBBR 算法使用最大带宽和往返时间来建立网络的显式模型。每次对包传递进行累积或选择性确认，都会生成一个速率样本，该速率采样记录在数据包传输与该包确认之间的时间间隔内传递的数据量，从而使拥塞控制算法能够提供更高的吞吐量和更低的延迟。\n最大分段大小 最大分段大小 (MSS) 是在单个分段中 TCP 愿意接受的数据的字节数最大值。MSS应当足够小以避免IP分片，它会导致丢包或过多的重传。\n在 TCP 连接创建时，双端在 SYN 报文中用 MSS 选项宣布各自的 MSS ，这是从双端各自直接相连的数据链路层的最大传输单元(MTU)的尺寸减去固定的 IP 首部和 TCP 首部长度。以太网MTU为 1500 字节， MSS值可达 1460 字节。使用 IEEE 802.3 的 MTU 为 1492 字节，MSS 可达 1452 字节。\n如果目的IP地址为“非本地的”，MSS通常的默认值为 536（这个默认值允许 20 字节的 IP 首部和 20 字节的 TCP 首部以适合 576字节 IP 数据报）。此外，发送方可用传输路径 MTU 发现（RFC 1191）推导出从发送方到接收方的网络路径上的最小 MTU，以此动态调整 MSS 以避免网络 IP 分片。\nMSS 发布也被称作“MSS协商”（MSS negotiation）。严格讲，这并非是协商出来一个统一的MSS值，TCP 允许连接两端使用各自不同的MSS值。例如，这会发生在参与 TCP 连接的一台设备使用非常少的内存处理到来的 TCP 分组。\n选择确认 最初采取累计确认的 TCP 协议在丢包时效率很低。例如，假设通过10个分组发出了1万个字节的数据。如果第一个分组丢失，在纯粹的累计确认协议下，接收方不能说它成功收到了 1,000 到 9,999 字节，但未收到包含 0 到 999 字节的第一个分组。因而，发送方可能必须重传所有1万个字节。\n为此，TCP采取了 选择确认（selective acknowledgment，SACK） 选项。RFC 2018 对此定义为 允许接收方确认它成功收到的分组的不连续的块，以及基础 TCP 确认的成功收到最后连续字节序号。这种确认可以指出 SACK block，包含了已经成功收到的连续范围的开始与结束字节序号。在上述例子中，接收方可以发出 SACK 指出序号 1000 到 9999 ，发送方因此知道只需重发第一个分组(字节 0 到 999)。\nTCP 发送方会把乱序收包当作丢包，因此会重传乱序收到的包，导致连接的性能下降。重复SACK选项（duplicate-SACK option）是定义在RFC 2883中的SACK的一项扩展，可解决这一问题。接收方发出 D-SACK 指出没有丢包，接收方恢复到高传输率。 D-SACK 使用了 SACK 的第一个段来做标志：\n  如果 SACK 的第一个段的范围被 ACK 所覆盖，那么就是 D-SACK; 如果 SACK 的第一个段的范围被 SACK 的第二个段覆盖，那么就是 D-SACK D-SACK旨在告诉发送端：收到了重复的数据，数据包没有丢，丢的是ACK包；   SACK 选项并不是强制的。仅当双端都支持时才会被使用。 TCP 连接创建时会在 TCP 头中协商 SACK 细节。在 Linux下，可以通过 tcp_sack 参数打开 SACK 功能（Linux 2.4后默认打开）。Linux下的 tcp_dsack 参数用于开启D-SACK功能（Linux 2.4后默认打开）。选择确认也用于流控制传输协议 (SCTP)。\n参考  TCP TCP Protocol From Wikipedia Why TCP is important 《TCP IP 详解 第四版》  ","id":9,"section":"posts","summary":"TCP是什么 ? 传输控制协议（TCP）是互联网协议组中重要的组成部分之一。TCP的实现之初是为了补充互联网协议（IP）。因此，这一对组合经常被","tags":["networking","tcp"],"title":"About TCP Protocol","uri":"https://holicc.github.io/2020/03/about-tcp-protocol/","year":"2020"}],"tags":[{"title":"database","uri":"https://holicc.github.io/tags/database/"},{"title":"http","uri":"https://holicc.github.io/tags/http/"},{"title":"index","uri":"https://holicc.github.io/tags/index/"},{"title":"mysql","uri":"https://holicc.github.io/tags/mysql/"},{"title":"networking","uri":"https://holicc.github.io/tags/networking/"},{"title":"powershell","uri":"https://holicc.github.io/tags/powershell/"},{"title":"programing","uri":"https://holicc.github.io/tags/programing/"},{"title":"rocketMQ","uri":"https://holicc.github.io/tags/rocketmq/"},{"title":"rust","uri":"https://holicc.github.io/tags/rust/"},{"title":"system-design","uri":"https://holicc.github.io/tags/system-design/"},{"title":"tcp","uri":"https://holicc.github.io/tags/tcp/"},{"title":"web","uri":"https://holicc.github.io/tags/web/"}]}